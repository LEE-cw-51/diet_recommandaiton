import pandas as pd
import os
import glob
import re
from bs4 import BeautifulSoup
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì • (ìƒìœ„ í´ë” ì ‘ê·¼ìš©)
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹œë„
try:
    from config.settings import settings
    DATA_RAW_DIR = settings.DATA_RAW
except ImportError:
    # ì„¤ì • íŒŒì¼ì´ ì—†ì„ ê²½ìš° ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©
    DATA_RAW_DIR = os.path.join(os.path.dirname(__file__), '..', 'data_raw')

# CSV íŒŒì¼ ê²½ë¡œ
OUTPUT_CSV_FILE = os.path.join(DATA_RAW_DIR, 'burgerking_products.csv')

# ì˜ì–‘ì†Œ ì´ë¦„ê³¼ DB ì»¬ëŸ¼ëª… ë§¤í•‘
NUTRITION_KEYWORDS = {
    'ì—´ëŸ‰': 'calories', 'íƒ„ìˆ˜í™”ë¬¼': 'carbs', 'ë‹¹ë¥˜': 'sugars', 'ë‹¨ë°±ì§ˆ': 'protein', 
    'ì§€ë°©': 'fat', 'í¬í™”ì§€ë°©': 'saturated_fat', 'íŠ¸ëœìŠ¤ì§€ë°©': 'trans_fat', 
    'ì½œë ˆìŠ¤í…Œë¡¤': 'cholesterol', 'ë‚˜íŠ¸ë¥¨': 'sodium'
}

def extract_data_from_local_html(file_path):
    """ë¡œì»¬ HTML íŒŒì¼ì—ì„œ ë©”ë‰´ëª…, ì˜ì–‘ì†Œ, ì•Œë ˆë¥´ê¸° ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return None

    soup = BeautifulSoup(html_content, 'html.parser')
    
    # íŒŒì¼ëª…ì—ì„œ ë©”ë‰´ëª… ì¶”ì¶œ (ì˜ˆ: debug_bk_modal_ì™€í¼.html -> ì™€í¼)
    filename = os.path.basename(file_path)
    menu_name_raw = filename.replace('debug_bk_modal_', '').replace('.html', '')
    menu_name = menu_name_raw.replace('_', ' ')
    
    product_data = {
        'menu_name': menu_name
    }

    # 1. ëª¨ë‹¬ ì»¨í…ì¸  ì°¾ê¸°
    container = soup.select_one('.pop_cont')
    if not container:
        return product_data

    # 2. ì˜ì–‘ ì„±ë¶„ ì¶”ì¶œ: í…Œì´ë¸” íŒŒì‹± (Thead ê¸°ë°˜)
    tables = container.select('table')
    
    for table in tables:
        # í—¤ë”(thead) ë¶„ì„
        headers = [th.text.strip().replace('\n', '').replace(' ', '') for th in table.select('thead th')]
        
        # í—¤ë”ê°€ ìˆëŠ” ê²½ìš° (ì˜ì–‘ì„±ë¶„ í…Œì´ë¸”)
        if headers:
            col_map = {}
            for idx, h in enumerate(headers):
                for key, db_col in NUTRITION_KEYWORDS.items():
                    if key in h:
                        col_map[idx] = db_col
                        break
            
            # ë°ì´í„°(tbody) ì¶”ì¶œ
            rows = table.select('tbody tr')
            for row in rows:
                cells = row.select('td')
                
                # ë°ì´í„° ì…€ ê°œìˆ˜ ë³´ì • (ì²« ì—´ì´ ì´ë¦„ì¸ ê²½ìš° ë“±)
                offset = 0
                if len(cells) < len(headers): 
                    offset = 1 

                for col_idx, db_col in col_map.items():
                    cell_index = col_idx - offset
                    
                    if 0 <= cell_index < len(cells):
                        val_text = cells[cell_index].text.strip()
                        # ìˆ«ìë§Œ ì¶”ì¶œ (ê´„í˜¸ ë“± ì œê±°)
                        val_match = re.match(r'([\d.]+)', val_text)
                        if val_match:
                            product_data[db_col] = float(val_match.group(1))

        # í—¤ë”ê°€ ì—†ëŠ” ê²½ìš° (ì•Œë ˆë¥´ê¸° í…Œì´ë¸” ê°€ëŠ¥ì„±)
        else:
            rows = table.select('tbody tr')
            for row in rows:
                cols = row.select('td')
                if cols:
                    text_val = cols[0].text.strip()
                    # ì•Œë ˆë¥´ê¸° ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì €ì¥
                    if any(x in text_val for x in ['ë°€', 'ëŒ€ë‘', 'ìš°ìœ ', 'ë‚œë¥˜', 'ì‡ ê³ ê¸°']):
                        product_data['allergens_scraped'] = text_val

    # 3. ì•Œë ˆë¥´ê¸° ì •ë³´ 2ì°¨ í™•ì¸ (í…ìŠ¤íŠ¸ íŒŒì‹±)
    if 'allergens_scraped' not in product_data:
        full_text = container.get_text(separator=' | ', strip=True)
        if "ì•Œë ˆë¥´ê¸°" in full_text:
             product_data['allergens_scraped'] = full_text[:500]

    return product_data

def fill_nutrition_from_html():
    print(f"ğŸ“‚ ë°ì´í„° í´ë”: {DATA_RAW_DIR}")
    
    # 1. ê¸°ì¡´ CSV íŒŒì¼ ë¡œë“œ
    if not os.path.exists(OUTPUT_CSV_FILE):
        print(f"âŒ ì˜¤ë¥˜: ê¸°ì¡´ CSV íŒŒì¼({OUTPUT_CSV_FILE})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € í¬ë¡¤ëŸ¬(burgerking_crawler.py)ë¥¼ ì‹¤í–‰í•´ CSVë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.")
        return

    df = pd.read_csv(OUTPUT_CSV_FILE, encoding='utf-8-sig')
    print(f"ğŸ“Š ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ë©”ë‰´")

    # 2. ëª¨ë“  ë””ë²„ê·¸ HTML íŒŒì¼ ì°¾ê¸°
    html_pattern = os.path.join(DATA_RAW_DIR, "debug_bk_modal_*.html")
    html_files = glob.glob(html_pattern)
    
    if not html_files:
        print(f"âš ï¸ ê²½ê³ : '{html_pattern}' íŒ¨í„´ì— ë§ëŠ” HTML íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“„ ë””ë²„ê·¸ HTML íŒŒì¼ {len(html_files)}ê°œ ë°œê²¬. ë¶„ì„ ì‹œì‘...")

    update_count = 0
    
    # 3. HTML íŒŒì¼ ìˆœíšŒí•˜ë©° ë°ì´í„° ì¶”ì¶œ ë° ë³‘í•©
    for html_file in html_files:
        extracted_data = extract_data_from_local_html(html_file)
        
        if extracted_data:
            menu_name = extracted_data['menu_name']
            
            # ë©”ë‰´ëª…ì´ ì¼ì¹˜í•˜ëŠ” í–‰ ì°¾ê¸°
            # (ê³µë°± ì œê±° ë“± ì •ê·œí™”í•˜ì—¬ ë¹„êµ ì •í™•ë„ í–¥ìƒ)
            mask = df['menu_name'].apply(lambda x: x.replace(' ', '') == menu_name.replace(' ', ''))
            
            if mask.any():
                # ì¶”ì¶œëœ ì˜ì–‘ì†Œ ë° ì•Œë ˆë¥´ê¸° ë°ì´í„°ë¡œ ë®ì–´ì“°ê¸°
                for key, val in extracted_data.items():
                    if key in df.columns and key != 'menu_name': 
                        df.loc[mask, key] = val
                update_count += 1
                print(f"   âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: {menu_name}")
            else:
                print(f"   âš ï¸ ë§¤ì¹­ ì‹¤íŒ¨ (CSVì— ì—†ìŒ): {menu_name}")
            
    # 4. ìˆ˜ì •ëœ DataFrameì„ CSVë¡œ ì €ì¥
    df.to_csv(OUTPUT_CSV_FILE, index=False, encoding='utf-8-sig')
    print(f"\nğŸ‰ ë°ì´í„° ë®ì–´ì“°ê¸° ì™„ë£Œ!")
    print(f"   - ì´ ì—…ë°ì´íŠ¸ëœ ë©”ë‰´: {update_count}ê°œ")
    print(f"   - ì €ì¥ëœ íŒŒì¼: {OUTPUT_CSV_FILE}")

if __name__ == '__main__':
    fill_nutrition_from_html()