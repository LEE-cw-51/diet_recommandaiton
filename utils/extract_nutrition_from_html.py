import pandas as pd
import os
import glob
import re
from bs4 import BeautifulSoup
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ì„¤ì • íŒŒì¼ ë¡œë“œ (ê²½ë¡œ ì„¤ì •)
try:
    from config.settings import settings
    DATA_RAW_DIR = settings.DATA_RAW
except ImportError:
    DATA_RAW_DIR = os.path.join(os.path.dirname(__file__), '..', 'data_raw')

# ëŒ€ìƒ CSV íŒŒì¼ ê²½ë¡œ
CSV_FILE_PATH = os.path.join(DATA_RAW_DIR, 'burgerking_products.csv')

# ì˜ì–‘ì†Œ í—¤ë” ë§¤í•‘ (HTML í—¤ë” ì´ë¦„ -> DB ì»¬ëŸ¼ ì´ë¦„)
NUTRITION_MAP = {
    'ì—´ëŸ‰': 'calories',
    'ë‹¹ë¥˜': 'sugars', 'ë‹¹': 'sugars',
    'ë‹¨ë°±ì§ˆ': 'protein',
    'í¬í™”ì§€ë°©': 'saturated_fat',
    'ë‚˜íŠ¸ë¥¨': 'sodium',
    'ì¹´í˜ì¸': 'caffeine'
    # íƒ„ìˆ˜í™”ë¬¼, ì§€ë°© ë“±ì€ í‘œì— ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ë‚¨ìŒ
}

def parse_html_file(file_path):
    """HTML íŒŒì¼ í•˜ë‚˜ë¥¼ íŒŒì‹±í•˜ì—¬ ë©”ë‰´ë³„ ì˜ì–‘ì†Œ ì •ë³´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ({os.path.basename(file_path)}): {e}")
        return []

    soup = BeautifulSoup(content, 'html.parser')
    extracted_items = []

    # 1. ì˜ì–‘ì„±ë¶„ í…Œì´ë¸” ì°¾ê¸°
    tables = soup.select('table')
    
    for table in tables:
        # í—¤ë” ë¶„ì„ (ì»¬ëŸ¼ ì¸ë±ìŠ¤ ì°¾ê¸°)
        headers = [th.text.strip().replace('\n', '').replace(' ', '') for th in table.select('thead th')]
        
        # ì˜ì–‘ì†Œ ì»¬ëŸ¼ ì¸ë±ìŠ¤ ë§µí•‘
        col_indices = {}
        for idx, header in enumerate(headers):
            for key, db_col in NUTRITION_MAP.items():
                if key in header:
                    col_indices[idx] = db_col
                    break
        
        if not col_indices:
            continue # ì˜ì–‘ì†Œ í…Œì´ë¸”ì´ ì•„ë‹˜ (ì•Œë ˆë¥´ê¸° í…Œì´ë¸” ë“±)

        # 2. ë°ì´í„° í–‰(Row) ë¶„ì„
        rows = table.select('tbody tr')
        for row in rows:
            # ì œí’ˆëª… ì°¾ê¸° (ë³´í†µ ì²« ë²ˆì§¸ thë‚˜ tdì— ìˆìŒ)
            name_elem = row.select_one('th') or row.select_one('td')
            if not name_elem: continue
            
            menu_name = name_elem.text.strip()
            
            # í•´ë‹¹ í–‰ì˜ ë°ì´í„° ì…€(td) ê°€ì ¸ì˜¤ê¸°
            cells = row.select('td')
            
            # ë°ì´í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
            item_data = {
                'menu_name': menu_name,
                'calories': 0.0, 'carbs': 0.0, 'sugars': 0.0, 'protein': 0.0, 
                'fat': 0.0, 'saturated_fat': 0.0, 'trans_fat': 0.0, 
                'cholesterol': 0.0, 'sodium': 0.0
            }
            
            # ì…€ ë°ì´í„° ë§¤í•‘
            # (í—¤ë” ê°œìˆ˜ì™€ ì…€ ê°œìˆ˜ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ. ì œí’ˆëª… ì»¬ëŸ¼ì„ ì œì™¸í•˜ê³  ê³„ì‚°)
            # ë³´í†µ ì œí’ˆëª…(th) + ê°’(td, td...) êµ¬ì¡°ì„
            
            for header_idx, db_col in col_indices.items():
                # ì œí’ˆëª… ì»¬ëŸ¼(ì¸ë±ìŠ¤ 0)ì„ ì œì™¸í•˜ê³  ë§¤í•‘í•´ì•¼ í•¨ -> index - 1
                cell_idx = header_idx - 1
                
                if 0 <= cell_idx < len(cells):
                    val_text = cells[cell_idx].text.strip()
                    # ìˆ«ìë§Œ ì¶”ì¶œ (ê´„í˜¸ ì•ˆì˜ % ìˆ˜ì¹˜ ì œê±°)
                    # ì˜ˆ: "271(14)" -> 271
                    val_match = re.match(r'([\d.]+)', val_text)
                    if val_match:
                        item_data[db_col] = float(val_match.group(1))
            
            extracted_items.append(item_data)

    # 3. ì•Œë ˆë¥´ê¸° ì •ë³´ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë³´ë„ˆìŠ¤)
    allergens = ""
    pop_cont = soup.select_one('.pop_cont')
    if pop_cont:
        full_text = pop_cont.get_text(separator=' ', strip=True)
        if "ì•Œë ˆë¥´ê¸°" in full_text:
            # ê°„ë‹¨í•˜ê²Œ í…ìŠ¤íŠ¸ ì¼ë¶€ë§Œ ê°€ì ¸ì˜´ (ì •êµí•œ íŒŒì‹±ì€ ì–´ë ¤ì›€)
            allergens = full_text[:300]

    # ëª¨ë“  ì•„ì´í…œì— ì•Œë ˆë¥´ê¸° ì •ë³´ ê³µí†µ ì ìš© (ëª¨ë‹¬ í•˜ë‚˜ì— ì—¬ëŸ¬ ë©”ë‰´ê°€ ìˆëŠ” ê²½ìš° ì• ë§¤í•˜ì§€ë§Œ ì¼ë‹¨ ë„£ìŒ)
    for item in extracted_items:
        item['allergens_scraped'] = allergens

    return extracted_items

def merge_html_data_to_csv():
    print(f"ğŸ“‚ HTML íŒŒì¼ ê²€ìƒ‰ ê²½ë¡œ: {DATA_RAW_DIR}")
    
    # 1. ê¸°ì¡´ CSV ë¡œë“œ (ì—†ìœ¼ë©´ ìƒì„±)
    if os.path.exists(CSV_FILE_PATH):
        df = pd.read_csv(CSV_FILE_PATH, encoding='utf-8-sig')
        print(f"ğŸ“Š ê¸°ì¡´ CSV ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ë©”ë‰´")
    else:
        print("âš ï¸ ê¸°ì¡´ CSVê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆ íŒŒì¼ ìƒì„± ëª¨ë“œ.")
        df = pd.DataFrame(columns=['store_name', 'menu_name', 'price', 'calories', 'protein', 'sodium', 'sugars', 'saturated_fat', 'allergens_scraped'])

    # 2. ëª¨ë“  HTML íŒŒì¼ ì°¾ê¸°
    html_files = glob.glob(os.path.join(DATA_RAW_DIR, "*.html"))
    print(f"ğŸ“„ ì²˜ë¦¬í•  HTML íŒŒì¼: {len(html_files)}ê°œ")

    updated_count = 0
    
    for html_file in html_files:
        extracted_list = parse_html_file(html_file)
        
        for data in extracted_list:
            name = data['menu_name']
            
            # CSVì—ì„œ ë©”ë‰´ëª… ë§¤ì¹­ (ê³µë°± ì œê±° í›„ ë¹„êµ)
            # 'ì™€í¼ ì„¸íŠ¸' vs 'ì™€í¼ì„¸íŠ¸' ê°™ì€ ì°¨ì´ë¥¼ ì¤„ì´ê¸° ìœ„í•¨
            match_mask = df['menu_name'].str.replace(' ', '') == name.replace(' ', '')
            
            if match_mask.any():
                # ê¸°ì¡´ í–‰ ì—…ë°ì´íŠ¸
                for col, val in data.items():
                    if col in df.columns and col != 'menu_name':
                        df.loc[match_mask, col] = val
                updated_count += 1
                # print(f"   âœ… ì—…ë°ì´íŠ¸: {name}")
            else:
                # ì‹ ê·œ ë©”ë‰´ ì¶”ê°€ (ì„ íƒ ì‚¬í•­: ì›ì¹˜ ì•Šìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬)
                new_row = data.copy()
                new_row['store_name'] = 'BurgerKing'
                new_row['price'] = 0 # ê°€ê²© ì •ë³´ëŠ” HTMLì— ì—†ìŒ
                # df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
                # print(f"   â• ì‹ ê·œ ì¶”ê°€: {name}")
                pass

    # 3. ì €ì¥
    df.to_csv(CSV_FILE_PATH, index=False, encoding='utf-8-sig')
    print(f"\nğŸ‰ ì‘ì—… ì™„ë£Œ! ì´ {updated_count}ê°œ ë©”ë‰´ ë°ì´í„°ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ’¾ ì €ì¥ ê²½ë¡œ: {CSV_FILE_PATH}")

if __name__ == '__main__':
    merge_html_data_to_csv()